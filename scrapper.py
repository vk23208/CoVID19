# -*- coding: utf-8 -*-
"""COVID19-Stats-checkpoint.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14YjKacFlVwk2ldOCkUPE4yz8l30dggHW
"""

import requests
from bs4 import BeautifulSoup

#pipreqs is the package we will use to get a requirements.txt file of all the packages used in script
#first we need to install it
#!pip install pipreqs
#pipreqs location

country = input("Enter Country name or all: ")

allurl = 'https://www.worldometers.info/coronavirus/#countries'
url = "https://www.worldometers.info/coronavirus/country/" + str(country) + '/'
headers = {"User-Agent" : "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.106 Safari/537.36"}

if country == "all":
    page = requests.get(allurl, headers = headers)    
    soup = BeautifulSoup(page.content, 'html.parser')

    numbers = soup.find_all("div",attrs = {"id":"maincounter-wrap"})
    data = []
    for i in numbers:
        a = i.get_text().strip().replace("\n"," ")
        data.append(a)
    print(country.capitalize() + str(" world data: "))         
    print(data)
    print("Death Rate: " + str(int(data[1].split()[1].replace(",",""))/int(data[0].split()[2].replace(",",""))*100))
    print("Recovery Rate: " + str(int(data[2].split()[1].replace(",",""))/int(data[0].split()[2].replace(",",""))*100))
    
else:
    page = requests.get(url, headers = headers)    
    soup = BeautifulSoup(page.content, 'html.parser')

    numbers = soup.find_all("div",attrs = {"id":"maincounter-wrap"})
    data = []
    for i in numbers:
        a = i.get_text().strip().replace("\n"," ")
        data.append(a)
    print(country.capitalize() + str(" data: "))
    print(data)
    print("Death Rate: " + str(int(data[1].split()[1].replace(",",""))/int(data[0].split()[2].replace(",",""))*100))
    print("Recovery Rate: " + str(int(data[2].split()[1].replace(",",""))/int(data[0].split()[2].replace(",",""))*100))













